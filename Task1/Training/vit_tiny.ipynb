{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI vs Real Image Detection\n\n## Project Overview\nThis notebook demonstrates an image classification project using Vision Transformer (ViT) to distinguish between AI-generated and real images.\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Install and Import Required Libraries\n","metadata":{}},{"cell_type":"code","source":"# Install necessary packages\n!pip install -U -q evaluate transformers datasets>=2.14.5 mlflow 2>/dev/null\n\n# Import required libraries\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport gc\nimport numpy as np\nimport pandas as pd\nimport itertools\nfrom collections import Counter\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import (\n    accuracy_score,\n    roc_auc_score,\n    confusion_matrix,\n    classification_report,\n    f1_score\n)\nimport time\n# Machine Learning and Deep Learning Libraries\nfrom imblearn.over_sampling import RandomOverSampler\nimport evaluate\nfrom datasets import Dataset, Image as data_Image, ClassLabel\nfrom transformers import (\n    TrainingArguments,\n    Trainer,\n    ViTImageProcessor,\n    ViTForImageClassification,\n    DefaultDataCollator\n)\nimport torch\nfrom torch.utils.data import DataLoader\nimport torchvision.transforms as T\nfrom transformers import pipeline\nfrom safetensors.torch import load_file, save_file\n\n\n# Image Processing Libraries\nfrom PIL import Image, ImageFile, ImageFilter\nimport cv2\nimport io\nimport random\nfrom pathlib import Path\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:39:56.267050Z","iopub.execute_input":"2024-12-06T09:39:56.267382Z","iopub.status.idle":"2024-12-06T09:40:15.531923Z","shell.execute_reply.started":"2024-12-06T09:39:56.267343Z","shell.execute_reply":"2024-12-06T09:40:15.531101Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## 2. Data Preparation\n","metadata":{}},{"cell_type":"code","source":"# Enable loading truncated images\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n# Initialize empty lists for file names and labels\ndef load_image_data(directory, subset='train'):\n    file_names = []\n    labels = []\n    \n    for file in sorted(Path(directory).glob(f'{subset}/*/*.*')):\n        label = str(file).split('/')[-2]\n        labels.append(label)\n        file_names.append(str(file))\n    \n    df = pd.DataFrame.from_dict({\"image\": file_names, \"label\": labels})\n    df = df.sample(frac=1).reset_index(drop=True)\n    \n    # For demonstration, using only a subset of data\n    df = df[:1024] if subset == 'train' else df[:128]\n    \n    return df\n\n# Load train and test datasets\ndirectory = '/kaggle/input/cifake-real-and-ai-generated-synthetic-images/'\ntrain_df = load_image_data(directory, 'train')\ntest_df = load_image_data(directory, 'test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:40:15.533630Z","iopub.execute_input":"2024-12-06T09:40:15.534698Z","iopub.status.idle":"2024-12-06T09:40:18.152085Z","shell.execute_reply.started":"2024-12-06T09:40:15.534655Z","shell.execute_reply":"2024-12-06T09:40:18.151088Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## 3. Label Mapping and Data Processing\n","metadata":{}},{"cell_type":"code","source":"# Create label mappings\nlabels_list = list(set(train_df['label']))\nlabel2id = {label: i for i, label in enumerate(labels_list)}\nid2label = {i: label for label, i in label2id.items()}\n\n# Create class labels\nClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n\n# Map labels to numeric IDs\ndef map_label2id(example):\n    example['label'] = ClassLabels.str2int(example['label'])\n    return example\n\n# Oversample minority class\ndef oversample_dataset(df):\n    y = df[['label']]\n    df = df.drop(['label'], axis=1)\n    \n    ros = RandomOverSampler(random_state=42)\n    df, y_resampled = ros.fit_resample(df, y)\n    \n    df['label'] = y_resampled\n    gc.collect()\n    \n    dataset = Dataset.from_pandas(df).cast_column(\"image\", data_Image())\n    dataset = dataset.map(map_label2id, batched=True)\n    dataset = dataset.cast_column('label', ClassLabels)\n    \n    return dataset\n\n# Create datasets\ntrain_data = oversample_dataset(train_df)\ntest_data = oversample_dataset(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:40:18.153373Z","iopub.execute_input":"2024-12-06T09:40:18.153738Z","iopub.status.idle":"2024-12-06T09:40:18.920391Z","shell.execute_reply.started":"2024-12-06T09:40:18.153700Z","shell.execute_reply":"2024-12-06T09:40:18.919566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1060 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ddb6666ef0284687b0e5a929e835f3df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/1060 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e85b4e69c7114f2ab0b5220be6047e79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/134 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed448bffe9f14b898e7214de820aa615"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/134 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"547f50b6e2a74c6a8e0500a6526a2509"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 4. Image Augmentation and Preprocessing\n","metadata":{}},{"cell_type":"code","source":"# Custom image augmentation classes\nclass JPEGCompression:\n    def __init__(self, quality_range=(50, 100), p=0.5, use_pil_jpeg=True):\n        self.quality_range = quality_range\n        self.p = p\n        self.use_pil_jpeg = use_pil_jpeg\n    \n    def __call__(self, img):\n        if random.random() > self.p:\n            return img\n            \n        quality = random.randint(self.quality_range[0], self.quality_range[1])\n        \n        if self.use_pil_jpeg:\n            buffer = io.BytesIO()\n            img.save(buffer, format='JPEG', quality=quality)\n            buffer.seek(0)\n            img = Image.open(buffer)\n        else:\n            img_np = np.array(img)\n            encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]\n            _, encoded_img = cv2.imencode('.jpg', cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR), encode_param)\n            decoded_img = cv2.imdecode(encoded_img, cv2.IMREAD_COLOR)\n            img = Image.fromarray(cv2.cvtColor(decoded_img, cv2.COLOR_BGR2RGB))\n            \n        return img\n\nclass RandomGaussianBlur:\n    def __init__(self, sigma_range=(0, 1), p=0.5):\n        self.sigma_range = sigma_range\n        self.p = p\n    \n    def __call__(self, img):\n        if random.random() > self.p:\n            return img\n            \n        sigma = random.uniform(self.sigma_range[0], self.sigma_range[1])\n        return img.filter(ImageFilter.GaussianBlur(radius=sigma))\n\nclass ProbabilisticColorJitter:\n    def __init__(self, brightness=0.05, contrast=0.05, saturation=0.05, p=0.2):\n        self.color_jitter = T.ColorJitter(\n            brightness=brightness, \n            contrast=contrast, \n            saturation=saturation\n        )\n        self.p = p\n\n    def __call__(self, img):\n        if random.random() < self.p:\n            return self.color_jitter(img)\n        return img\n\n# ViT model configuration\nmodel_str = 'WinKawaks/vit-tiny-patch16-224'\nprocessor = ViTImageProcessor.from_pretrained(model_str, num_labels=len(labels_list), ignore_mismatched_sizes=True)\n\nimage_mean, image_std = processor.image_mean, processor.image_std\nsize = processor.size[\"height\"]\n\nnormalize = T.Normalize(mean=image_mean, std=image_std)\n\n# Define transformations\n_train_transforms = T.Compose([\n    RandomGaussianBlur(p=0.1),\n    ProbabilisticColorJitter(p=0.1),\n    JPEGCompression(p=0.1, use_pil_jpeg=random.choice([True, False])),\n    T.Resize((size, size)),\n    T.ToTensor(),\n    normalize\n])\n\n_val_transforms = T.Compose([\n    T.Resize((size, size)),\n    T.ToTensor(),\n    normalize\n])\n\n# Transformation functions\ndef train_transforms(examples):\n    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples\n\ndef val_transforms(examples):\n    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples\n\n# Set transforms\ntrain_data.set_transform(train_transforms)\ntest_data.set_transform(val_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:40:18.922159Z","iopub.execute_input":"2024-12-06T09:40:18.922442Z","iopub.status.idle":"2024-12-06T09:40:19.187179Z","shell.execute_reply.started":"2024-12-06T09:40:18.922415Z","shell.execute_reply":"2024-12-06T09:40:19.186329Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f5b9327c0414f1cb65472946b87d5a5"}},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"## 5. Model Training Configuration\n","metadata":{}},{"cell_type":"code","source":"# Collate function\ndef collate_fn(examples):\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    labels = torch.tensor([example['label'] for example in examples])\n    return {\"pixel_values\": pixel_values, \"labels\": labels}\n\n# Load pre-trained model\nmodel = ViTForImageClassification.from_pretrained(\n    model_str, \n    num_labels=len(labels_list), \n    ignore_mismatched_sizes=True\n)\n\n# Configure label mappings\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id\n\n# Compute metrics function\naccuracy = evaluate.load(\"accuracy\")\ndef compute_metrics(eval_pred):\n    predictions = eval_pred.predictions\n    label_ids = eval_pred.label_ids\n    predicted_labels = predictions.argmax(axis=1)\n    acc_score = accuracy.compute(predictions=predicted_labels, references=label_ids)['accuracy']\n    return {\"accuracy\": acc_score}\n\n# Training arguments\nargs = TrainingArguments(\n    output_dir=\"ai_vs_real_image_detection\",\n    logging_dir='./logs',\n    evaluation_strategy=\"epoch\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=32,\n    per_device_eval_batch_size=32,\n    num_train_epochs=5,\n    weight_decay=0.02,\n    warmup_steps=50,\n    remove_unused_columns=False,\n    save_strategy='epoch',\n    load_best_model_at_end=True,\n    save_total_limit=1,\n    report_to=\"mlflow\"\n)\n\n# Create Trainer\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:40:19.188077Z","iopub.execute_input":"2024-12-06T09:40:19.188299Z","iopub.status.idle":"2024-12-06T09:40:22.097053Z","shell.execute_reply.started":"2024-12-06T09:40:19.188276Z","shell.execute_reply":"2024-12-06T09:40:22.096331Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb2087c7acb94eefb94285a069b1c934"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/22.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1162f868de049549630f0a49796c287"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTForImageClassification were not initialized from the model checkpoint at WinKawaks/vit-tiny-patch16-224 and are newly initialized because the shapes did not match:\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n- classifier.weight: found shape torch.Size([1000, 192]) in the checkpoint and torch.Size([2, 192]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bf6deb5ae3c4fef97664ca97f6aa545"}},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## 6.Training And Evaluation\n","metadata":{}},{"cell_type":"code","source":"# Define a function to plot a confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):\n    # Create a figure with a specified size\n    plt.figure(figsize=figsize)\n    \n    # Display the confusion matrix as an image with a colormap\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    # Define tick marks and labels for the classes on the axes\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.0f'\n    # Add text annotations to the plot indicating the values in the cells\n    thresh = cm.max() / 2.0\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    # Label the axes\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    # Ensure the plot layout is tight\n    plt.tight_layout()\n    # Display the plot\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:40:22.098227Z","iopub.execute_input":"2024-12-06T09:40:22.098875Z","iopub.status.idle":"2024-12-06T09:40:22.105498Z","shell.execute_reply.started":"2024-12-06T09:40:22.098836Z","shell.execute_reply":"2024-12-06T09:40:22.104651Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Evaluate the pre-training model's performance\nprint(\"Pre-training Evaluation:\")\ntrainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:40:22.106658Z","iopub.execute_input":"2024-12-06T09:40:22.107057Z","iopub.status.idle":"2024-12-06T09:40:24.053662Z","shell.execute_reply.started":"2024-12-06T09:40:22.107007Z","shell.execute_reply":"2024-12-06T09:40:24.051924Z"}},"outputs":[{"name":"stdout","text":"Pre-training Evaluation:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [5/5 00:13]\n    </div>\n    "},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.8792052865028381,\n 'eval_model_preparation_time': 0.0037,\n 'eval_accuracy': 0.4925373134328358,\n 'eval_runtime': 1.8503,\n 'eval_samples_per_second': 72.42,\n 'eval_steps_per_second': 2.702}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Train the model\nprint(\"Training the model:\")\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:40:24.056205Z","iopub.execute_input":"2024-12-06T09:40:24.056440Z","iopub.status.idle":"2024-12-06T09:41:03.762767Z","shell.execute_reply.started":"2024-12-06T09:40:24.056416Z","shell.execute_reply":"2024-12-06T09:41:03.761970Z"}},"outputs":[{"name":"stdout","text":"Training the model:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='170' max='170' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [170/170 00:38, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Model Preparation Time</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.731746</td>\n      <td>0.003700</td>\n      <td>0.514925</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.512187</td>\n      <td>0.003700</td>\n      <td>0.716418</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.427313</td>\n      <td>0.003700</td>\n      <td>0.776119</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>0.382475</td>\n      <td>0.003700</td>\n      <td>0.850746</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>0.371928</td>\n      <td>0.003700</td>\n      <td>0.850746</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=170, training_loss=0.4414402232450597, metrics={'train_runtime': 38.3097, 'train_samples_per_second': 138.346, 'train_steps_per_second': 4.438, 'total_flos': 2.64460691755008e+16, 'train_loss': 0.4414402232450597, 'epoch': 5.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Evaluate the post-training model's performance\nprint(\"Post-training Evaluation:\")\ntrainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:41:03.763992Z","iopub.execute_input":"2024-12-06T09:41:03.764658Z","iopub.status.idle":"2024-12-06T09:41:04.224084Z","shell.execute_reply.started":"2024-12-06T09:41:03.764605Z","shell.execute_reply":"2024-12-06T09:41:04.223207Z"}},"outputs":[{"name":"stdout","text":"Post-training Evaluation:\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.37192752957344055,\n 'eval_model_preparation_time': 0.0037,\n 'eval_accuracy': 0.8507462686567164,\n 'eval_runtime': 0.434,\n 'eval_samples_per_second': 308.771,\n 'eval_steps_per_second': 11.521,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Make predictions on the test dataset\noutputs = trainer.predict(test_data)\n\n# Print the metrics from the predictions\nprint(\"Prediction Metrics:\")\nprint(outputs.metrics)\n\n# Extract true labels and predicted labels\ny_true = outputs.label_ids\ny_pred = outputs.predictions.argmax(1)\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred, average='macro')\n\n# Display accuracy and F1 score\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Plot confusion matrix if the number of labels is small\nif len(labels_list) <= 150:\n    cm = confusion_matrix(y_true, y_pred)\n    plot_confusion_matrix(cm, labels_list, figsize=(8, 6))\n\n# Display classification report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, target_names=labels_list, digits=4))\n\n# Save the trained model\ntrainer.save_model()\n\n# Path to the safetensors file\nsafetensors_path = \"ai_vs_real_image_detection/model.safetensors\"\n\n# Load the model from the safetensors file\nmodel_state = load_file(safetensors_path)\n\n# Convert to PyTorch and save as .pt\npt_path = \"vit tiny.pt\"\ntorch.save(model_state, pt_path)\n\nprint(f\"Model saved to {pt_path}\")\n# Load the .pt file to verify\nloaded_state = torch.load(pt_path)\n\n# Check if the state matches\nassert model_state.keys() == loaded_state.keys()\nprint(\"Model conversion verified!\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:41:04.227759Z","iopub.execute_input":"2024-12-06T09:41:04.228294Z","iopub.status.idle":"2024-12-06T09:41:05.169713Z","shell.execute_reply.started":"2024-12-06T09:41:04.228260Z","shell.execute_reply":"2024-12-06T09:41:05.168622Z"}},"outputs":[{"name":"stdout","text":"Prediction Metrics:\n{'test_loss': 0.37192752957344055, 'test_model_preparation_time': 0.0037, 'test_accuracy': 0.8507462686567164, 'test_runtime': 0.4519, 'test_samples_per_second': 296.504, 'test_steps_per_second': 11.064}\nAccuracy: 0.8507\nF1 Score: 0.8507\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification Report:\n              precision    recall  f1-score   support\n\n        REAL     0.8615    0.8358    0.8485        67\n        FAKE     0.8406    0.8657    0.8529        67\n\n    accuracy                         0.8507       134\n   macro avg     0.8511    0.8507    0.8507       134\nweighted avg     0.8511    0.8507    0.8507       134\n\nModel saved to vit tiny.pt\nModel conversion verified!\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## 7.Inferance","metadata":{}},{"cell_type":"code","source":"# Create an inference pipeline\n\npipe = pipeline('image-classification', model=\"ai_vs_real_image_detection\", device=-1)\n\n# Example inference on a test image\ntest_image = test_data[1][\"image\"]\nprint(\"Actual Label:\", id2label[test_data[1][\"label\"]])\n\n# Perform inference and measure time\nstart_time = time.time()\ninference_result = pipe(test_image)\nend_time = time.time()\n\nprint(\"Inference Result:\", inference_result)\nprint(\"Inference Time:\", end_time - start_time, \"seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T09:42:03.315830Z","iopub.execute_input":"2024-12-06T09:42:03.316174Z","iopub.status.idle":"2024-12-06T09:42:03.415517Z","shell.execute_reply.started":"2024-12-06T09:42:03.316148Z","shell.execute_reply":"2024-12-06T09:42:03.414645Z"}},"outputs":[{"name":"stderr","text":"Device set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"Actual Label: REAL\nInference Result: [{'label': 'REAL', 'score': 0.5210098028182983}, {'label': 'FAKE', 'score': 0.12555311620235443}]\nInference Time: 0.0262758731842041 seconds\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}